{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "conceptual-landscape",
   "metadata": {},
   "source": [
    "# Split Data into Train and Test Set\n",
    "\n",
    "The extracted images collect from two datasets (fe_ckplus_kdef and mma) have been saved in the folder 'dataset'. This notebook randomly select images for train and test dataset. The images are saved in two folders: test and train. \n",
    "\n",
    "Datasets:\n",
    " - mma dataset: https://www.kaggle.com/mahmoudima/mma-facial-expression\n",
    " - fer_ckplus_kdef: https://www.kaggle.com/sudarshanvaidya/corrective-reannotation-of-fer-ck-kdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "honest-prototype",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58922, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>img_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset/anger/</td>\n",
       "      <td>AF01ANS.png</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset/anger/</td>\n",
       "      <td>AF02ANS.png</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset/anger/</td>\n",
       "      <td>AF03ANS.png</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset/anger/</td>\n",
       "      <td>AF04ANS.png</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset/anger/</td>\n",
       "      <td>AF05ANS.png</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             path     img_name  label\n",
       "0  dataset/anger/  AF01ANS.png  anger\n",
       "1  dataset/anger/  AF02ANS.png  anger\n",
       "2  dataset/anger/  AF03ANS.png  anger\n",
       "3  dataset/anger/  AF04ANS.png  anger\n",
       "4  dataset/anger/  AF05ANS.png  anger"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "    \n",
    "# get a list of file in the directory\n",
    "folders = os.listdir('dataset')\n",
    "\n",
    "paths = list()\n",
    "img_names = list()\n",
    "labels = list()\n",
    "\n",
    "# get a list of image names in the folder 'dataset'\n",
    "for folder in folders:\n",
    "    path = 'dataset/' + folder + '/'\n",
    "    file_names = os.listdir(path)\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        paths.append(path)\n",
    "        img_names.append(file_name)\n",
    "        labels.append(folder.split('_')[0])\n",
    "\n",
    "# create a data frame that store image's name, path and label\n",
    "df = pd.DataFrame({'path': paths, 'img_name': img_names, 'label': labels})\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alive-burlington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset/happiness/         9049\n",
       "dataset/surprise_mma/      8113\n",
       "dataset/anger_mma/         6566\n",
       "dataset/sadness/           5403\n",
       "dataset/neutrality/        5072\n",
       "dataset/fear_mma/          4859\n",
       "dataset/anger/             4725\n",
       "dataset/disgust_mma/       4542\n",
       "dataset/surprise/          4226\n",
       "dataset/fear/              3454\n",
       "dataset/neutrality_mma/    1988\n",
       "dataset/disgust/            795\n",
       "dataset/contempt/           130\n",
       "Name: path, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['path'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desired sample size\n",
    "n_sample = 5337\n",
    "\n",
    "temp_dfs = list()\n",
    "df2 = None\n",
    "\n",
    "train_data = None\n",
    "test_data = None\n",
    "\n",
    "for path in list(df['path'].unique()):\n",
    "    size = df[df['path'] == path].shape[0]\n",
    "    \n",
    "    if '_mma' not in path and 'contempt' not in path and size != n_sample:\n",
    "        temp = df[df['path'] == path]\n",
    "        \n",
    "        # under sample classes that have more than 5337 images\n",
    "        if size >= n_sample:\n",
    "            temp = temp.sample(n=n_sample)\n",
    "        \n",
    "        # for classes that have less than 5337 images\n",
    "        # randomly the remaining number of images from mma dataset\n",
    "        if size < n_sample:\n",
    "            path2 = path[:-1] + '_mma/'\n",
    "            temp2 = df[df['path'] == path2]\n",
    "            n_sample2 = n_sample - size\n",
    "            \n",
    "            temp2 = temp2.sample(n=n_sample2)\n",
    "            temp = pd.concat([temp, temp2], axis=0)\n",
    "        \n",
    "        if df2 is not None:\n",
    "            # concatenating df1 and df2 along rows\n",
    "            df2 = pd.concat([df2, temp], axis=0).reset_index().drop(['index'], axis=1)\n",
    "        else:\n",
    "            df2 = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "connected-speech",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37359, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "wrapped-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df2['label']\n",
    "X = df2.drop('label',axis=1)\n",
    "\n",
    "# split data into 70% test and 30% train\n",
    "x_train, x_test, y_train, y_test=train_test_split(X, y, train_size=0.70, test_size=0.30, \n",
    "                                                  stratify=y, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "descending-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([x_train, y_train], axis=1).reset_index().drop(['index'], axis=1)\n",
    "test = pd.concat([x_test, y_test], axis=1).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "# save data frame as pickle file\n",
    "train.to_pickle(\"data/train_data.pkl\")\n",
    "test.to_pickle(\"data/test_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "liked-microphone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "paths = ['data/train/', 'data/test/']\n",
    "data = [train, test]\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    \n",
    "    for index, row in data[i].iterrows():\n",
    "        img_file = row['path'] + row['img_name']\n",
    "        img = Image.open(img_file)\n",
    "        \n",
    "        # convert image to gray scale\n",
    "        img = img.convert('L')\n",
    "        \n",
    "        # resize image to 224x224\n",
    "        img = img.resize((224, 224), Image.ANTIALIAS)\n",
    "        \n",
    "        # save image into train/test directory under folder for specified label\n",
    "        save_path = path + row['label'] + '/'\n",
    "        \n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        \n",
    "        # save image\n",
    "        img.save(save_path + row['img_name'], 'PNG')\n",
    "        img.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
